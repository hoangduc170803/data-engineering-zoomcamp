## Module 4 Homework

# üìñ Q1

## üß† 1Ô∏è‚É£ Context:

We have the following `sources.yml` file:

```yaml
version: 2

sources:
  - name: raw_nyc_tripdata
    database: "{{ env_var('DBT_BIGQUERY_PROJECT', 'dtc_zoomcamp_2025') }}"
    schema:   "{{ env_var('DBT_BIGQUERY_SOURCE_DATASET', 'raw_nyc_tripdata') }}"
    tables:
      - name: ext_green_taxi
      - name: ext_yellow_taxi
```

And we have the following environment variables set:

```bash
export DBT_BIGQUERY_PROJECT=myproject
export DBT_BIGQUERY_SOURCE_DATASET=my_nyc_tripdata
```

### üõ†Ô∏è SQL Query:

```sql
SELECT *
FROM {{ source('raw_nyc_tripdata', 'ext_green_taxi') }}
```

## üîç 2Ô∏è‚É£ How dbt Resolves the Source()

The `source()` function in dbt compiles into a fully-qualified table reference using the following structure:

```sql
SELECT * FROM `<database>.<schema>.<table>`
```

### üìú Breakdown:

| Component | Definition              | Resolution              |
|-----------|-------------------------|--------------------------|
| **Database** | Defined in `sources.yml` | `myproject` (from `DBT_BIGQUERY_PROJECT`) |
| **Schema**   | Defined in `sources.yml` | `my_nyc_tripdata` (from `DBT_BIGQUERY_SOURCE_DATASET`) |
| **Table**    | Provided in `sources.yml` | `ext_green_taxi`           |

### ‚öôÔ∏è Compilation Steps:

1. **Database:**
   - dbt reads the `database` field from the `sources.yml` file.
   - It finds `{{ env_var('DBT_BIGQUERY_PROJECT', 'dtc_zoomcamp_2025') }}`.
   - It checks the environment variable `DBT_BIGQUERY_PROJECT`, which is set to `myproject`.
   - Final value: **`myproject`**.

2. **Schema:**
   - dbt reads the `schema` field from the `sources.yml` file.
   - It finds `{{ env_var('DBT_BIGQUERY_SOURCE_DATASET', 'raw_nyc_tripdata') }}`.
   - It checks the environment variable `DBT_BIGQUERY_SOURCE_DATASET`, which is set to `my_nyc_tripdata`.
   - Final value: **`my_nyc_tripdata`**.

3. **Table:**
   - dbt finds the table name `ext_green_taxi` directly from `sources.yml`.
   - No dynamic value or environment variable is involved here.

### ‚úÖ Compiled SQL:

```sql
SELECT * FROM myproject.my_nyc_tripdata.ext_green_taxi
```

# üìñ Q2
## üß† 1Ô∏è‚É£ Context

We need to modify the following dbt model (`fct_recent_taxi_trips.sql`) to allow Analytics Engineers to dynamically control the date range:

- **Development:** Process the last 7 days.
- **Production:** Process the last 30 days.

### üîç Original Query:

```sql
SELECT *
FROM {{ ref('fact_taxi_trips') }}
WHERE pickup_datetime >= CURRENT_DATE - INTERVAL '30 days'
```

## üéØ 2Ô∏è‚É£ Requirements

- Command-line arguments should take precedence over environment variables.
- Environment variables should take precedence over default values.

## üöÄ 3Ô∏è‚É£ Options Analysis

| **Option** | **Query** | **Explanation** |
|------------|----------|-----------------|
| 1 | `ORDER BY pickup_datetime DESC LIMIT {{ var("days_back", 30) }}` | Irrelevant to date filtering. |
| 2 | `WHERE pickup_datetime >= CURRENT_DATE - INTERVAL '{{ var("days_back", 30) }}' DAY` | Uses `var()` but ignores `env_var()`. |
| 3 | `WHERE pickup_datetime >= CURRENT_DATE - INTERVAL '{{ env_var("DAYS_BACK", "30") }}' DAY` | Relies only on environment variables. |
| 4 | `WHERE pickup_datetime >= CURRENT_DATE - INTERVAL '{{ var("days_back", env_var("DAYS_BACK", "30")) }}' DAY` | ‚úÖ **Correct - follows the right priority order: command > env > default**. |
| 5 | `WHERE pickup_datetime >= CURRENT_DATE - INTERVAL '{{ env_var("DAYS_BACK", var("days_back", "30")) }}' DAY` | Environment variable takes precedence over command-line argument. |


## üèÜ 4Ô∏è‚É£ Correct Answer

The correct solution is:

```sql
WHERE pickup_datetime >= CURRENT_DATE - INTERVAL '{{ var("days_back", env_var("DAYS_BACK", "30")) }}' DAY
```

### üß† **Explanation:**
1. **`var("days_back", ...)`**: Allows passing parameters via the command line.
2. **`env_var("DAYS_BACK", ...)`**: Uses the environment variable if the command-line parameter is not provided.
3. **`"30"`**: Default value if both are missing.

### üõ†Ô∏è **Priority Order:**
1. **Command-line argument**: Run with `--vars '{"days_back": "7"}'`.
2. **Environment variable**: Set with `export DAYS_BACK=7`.
3. **Default value**: Uses `30` if both are missing.

## üß™ 5Ô∏è‚É£ Debugging Tips

### üõ†Ô∏è **Check Compilation**
```bash
dbt compile --select fct_recent_taxi_trips
```

### üõ†Ô∏è **Test Parameter Override**
```bash
dbt run --select fct_recent_taxi_trips --vars '{"days_back": "7"}'
```

### üõ†Ô∏è **Check Environment Variable**
```bash
echo $DAYS_BACK
```

### üõ†Ô∏è **Run dbt Debug**
```bash
dbt debug
```

## üîç 6Ô∏è‚É£ Conclusion

- **Best Query:**

```sql
WHERE pickup_datetime >= CURRENT_DATE - INTERVAL '{{ var("days_back", env_var("DAYS_BACK", "30")) }}' DAY
```

- **Priority:** Command-line argument > environment variable > default value.
- **Flexible solution** for both development (7 days) and production (30 days).


## üìñ Q3
Based on the provided lineage graph, we know that the final table **`fct_taxi_monthly_zone_revenue`** depends on several upstream tables, including:

- **`dim_taxi_trips`**
- **`dim_fhv_trips`**
- **`dim_zone_lookup`** *(from the seed `taxi_zone_lookup`)*

### ‚öôÔ∏è **Key Insight:**

- **`taxi_zone_lookup`** is **the only materialized seed file**.
- **The other models are either staging or core transformations.**

---

## üõ†Ô∏è **Understanding dbt Commands**

Let's break down each command:

### üü¢ 1Ô∏è‚É£ **`dbt run`**

üîç **What it does:**

- Runs all models **except seeds** and **tests**.
- It **would materialize** **`fct_taxi_monthly_zone_revenue`** along with **all dependencies** if needed.

‚úÖ **Applies:** ‚úîÔ∏è *(This command works fine for the final model.)*

---

### üü¢ 2Ô∏è‚É£ **`dbt run --select +models/core/dim_taxi_trips.sql+ --target prod`**

üîç **What it does:**

- **`dim_taxi_trips.sql`** is a **core model**.
- The **`+`** selector indicates **include immediate upstream/downstream dependencies**.
- dbt run --select +path:models/core/dim_taxi_trips.sql+ --target prod
  
‚úÖ **Applies:** ‚úîÔ∏è 


---

### üü¢ 3Ô∏è‚É£ **`dbt run --select +models/core/fct_taxi_monthly_zone_revenue.sql`**

üîç **What it does:**

- Runs **`fct_taxi_monthly_zone_revenue`** and its **dependencies**.
- The **`+`** selector ensures **upstream models are built** if needed.

‚úÖ **Applies:** ‚úîÔ∏è *(This command will correctly materialize the final model.)*

---

### üü¢ 4Ô∏è‚É£ **`dbt run --select +models/core/`**

üîç **What it does:**

- Runs **all models within the `core` directory**, including **`dim_taxi_trips`** and **`fct_taxi_monthly_zone_revenue`**.

‚úÖ **Applies:** ‚úîÔ∏è *(This command includes the final model.)*

---

### ‚ùå 5Ô∏è‚É£ `dbt run --select models/staging/+`

üîç **What it does:**

- Runs **all models in the `staging` folder**.
- **Does NOT materialize `fct_taxi_monthly_zone_revenue`** (it's in the `core` folder).

‚ùå **Does NOT apply:** ‚úò *(This command is limited to staging and cannot build the final table.)*

---

## üéØ **Conclusion**

The **commands that do NOT apply** are:


### ‚ùå **`dbt run --select models/staging/+`**

---



```bash
dbt run --select +models/core/
```

---

### ‚úÖ **Final Answer:**

**`dbt run --select models/staging/+`** üö´

# üìñ Q4

## üõ†Ô∏è Macro Behavior Explained

The behavior of dataset selection in dbt based on the `model_type` can be summarized as follows:

### 1Ô∏è‚É£ **For `model_type == 'core'`:**

The macro returns:

```jinja
env_var('DBT_BIGQUERY_TARGET_DATASET')
```

**Important Note:**
- This call does **not** provide a fallback value.  
- **Implication:** `DBT_BIGQUERY_TARGET_DATASET` **must be defined**, or dbt **will fail to compile**.

---

### 2Ô∏è‚É£ **For other `model_type` values (e.g., `staging`, `dim_`, `fct_`):**

The macro returns:

```jinja
env_var('DBT_BIGQUERY_STAGING_DATASET', env_var('DBT_BIGQUERY_TARGET_DATASET'))
```

**Explanation:**
- dbt will first attempt to get the value of `DBT_BIGQUERY_STAGING_DATASET`.  
- **If set:** It uses that value.  
- **If not:** It falls back to the value of `DBT_BIGQUERY_TARGET_DATASET`.  

**Implication:** Setting `DBT_BIGQUERY_STAGING_DATASET` **is optional**.  

---

## ‚úÖ **Statement Evaluation**

Let's evaluate the given statements:

1. **"Setting a value for `DBT_BIGQUERY_TARGET_DATASET` env var is mandatory, or it'll fail to compile"**  
   - **Answer:** ‚úÖ **True**.  
   - **Explanation:** Core models use `DBT_BIGQUERY_TARGET_DATASET` directly with no fallback.

2. **"Setting a value for `DBT_BIGQUERY_STAGING_DATASET` env var is mandatory, or it'll fail to compile"**  
   - **Answer:** ‚ùå **False**.  
   - **Explanation:** Non-core models fall back to `DBT_BIGQUERY_TARGET_DATASET` if the staging variable is missing.

3. **"When using core, it materializes in the dataset defined in `DBT_BIGQUERY_TARGET_DATASET`"**  
   - **Answer:** ‚úÖ **True**.  
   - **Explanation:** Core models directly use this variable.

4. **"When using stg, it materializes in the dataset defined in `DBT_BIGQUERY_STAGING_DATASET`, or defaults to `DBT_BIGQUERY_TARGET_DATASET`"**  
   - **Answer:** ‚úÖ **True**.  
   - **Explanation:** Non-core models check the staging variable first.

5. **"When using staging, it materializes in the dataset defined in `DBT_BIGQUERY_STAGING_DATASET`, or defaults to `DBT_BIGQUERY_TARGET_DATASET`"**  
   - **Answer:** ‚úÖ **True**.  
   - **Explanation:** Same behavior as statement 4.

---

## üß† **Summary of Evaluation**

- **True Statements:** 1Ô∏è‚É£, 3Ô∏è‚É£, 4Ô∏è‚É£, 5Ô∏è‚É£  
- **False Statement:** 2Ô∏è‚É£

### üîë **Key Takeaways:**
1. **`DBT_BIGQUERY_TARGET_DATASET`** is **mandatory**.  
2. **`DBT_BIGQUERY_STAGING_DATASET`** is **optional**, and dbt will fall back to **`DBT_BIGQUERY_TARGET_DATASET`** if it is not defined.  
3. Core models always use **`DBT_BIGQUERY_TARGET_DATASET`**.  
4. Non-core models (e.g., staging, dim, fct) prefer **`DBT_BIGQUERY_STAGING_DATASET`** if available.

---


## üéØ **Conclusion**

Understanding how `env_var()` works in dbt is crucial for managing environments dynamically.  
- **Always set `DBT_BIGQUERY_TARGET_DATASET`** when working with core models.  
- **Use `DBT_BIGQUERY_STAGING_DATASET`** for better control over non-core datasets but rely on the fallback if necessary.  




